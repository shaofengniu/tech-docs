# 大数据无缝迁移

## 背景

计数服务的存储引擎由ndb向redis迁移，数据量近30G，纯计数服务，400M个key，
峰值流量6000qps。单redis写入速度7万/s，实例大小上限5G。

## 问题

迁移方案面临如下问题：

1. 迁移过程对产品线透明，不需要产品线进行任何代码修改和操作。
2. 迁移过程中，服务不能中断，否则会影响前端页面显示
3. 导数据的过程中尽可能的减少pv的损失

## 方案

首先，我们在archproxy中实现了两个存储后端的兼容层，通过协议转换使两种
引擎对外暴露统一的接口，这样产品线就不需要对代码进行修改。

对于第二个问题，我们采取的方案是，在迁移的过程中ndb服务不停止，将数据
从ndb导入redis后，直接在archproxy中进行流量切换，这样计数服务就不存在
服务中断的情况，整个切换过程不需要产品线配合操作。并且切换过程中，是依
次对每一台archproxy进行切换，相当于小流量上线，能够在出现问题的时候极
大的降低对产品线的影响。

对于第三个问题，我们解决方案的解决方案是：

1. 尽可能提升导数据的速度，在不压垮线上机器的情况下尽可能的减少操作耗
时
2. 在ndb开始导出数据的同时开启请求日志，记录这段时间往后的所有写操作的
信息。等数据导入redis之后，进行若干次的日志回放，将这段时间的流量写入
redis，即增量导入。

由于单个redis实例的写入速度大致7万，400M个key大概需要90分钟，这个耗时
比较难受，所以就将redis拆分为8个分片，然后使用8个线程，并行的从bdb里面
读取数据，写入各自负责的分片。这样总体的写入速度达到了50万/s，整个导数
据的过程只需要15分钟就可以完成。

为了增加对增量导入的支持，我们对ndb进行了升级，使其能够通过外部信号触
发来开关access log的输出，这样就可以使用导数据工具将log中的命令写入
redis。

## 实际过程

上述方法结合起来，已经基本上能够解决大数据的“无缝”迁移问题，但实际操作
中遇到的一些问题使得我们没有办法100%的实施上述方案。

例如，虽然我们发布了新版本的ndb以支持通过access log来进行增量导入，但
是由于线上ndb服务重启的风险比较大，最后还是放弃了升级ndb来进行增量同步。

不过，不过这一决定是建立在我们的工具可以在15分钟内搞定数据导入，低峰期
的话，这段时间的损失是可以接受的基础上的。如果我们需要90分钟才能完成数
据导入，那么也就只能冒着风险升级ndb了。

另外，导数据的速度是一把双刃剑，速度过慢，可能会损失大量pv，而速度过快
的话，可能会直接把线上机器压垮。

对于这一问题，我们选择在从机上进行操作，这台机器的流量比较小，且同机基
本没有其他服务，这样即使服务器被压垮，也不会对线上服务产生影响。或者可
以在一台空闲机器上，新加一台从机来导数据，这样的影响会更小。

最终，虽然我们设想了比较周全方案，但实际操作下来还是使用了最为简单粗暴
的方式。

## 通用化

这里说的数据迁移方案推广到其他引擎间的数据迁移也是基本适用的，但需要根
据具体的对数据安全的需求进行相应的调整。例如，有些服务的要求就是可以接
受服务中断，但不允许数据丢失，对于这种情况我们可能就只能先停服务，导数
据，再启动服务了。

## 问题

这里总结一下整个迁移过程中在各个方面遇到的问题

1. 服务兼容层，这可能是整个迁移过程中风险最大的地方，因为你必须能够做
到新服务与老服务对外完全兼容。为了做到这一点，就需要直接与每一个产品线
的负责人去聊，了解他们对接口的使用情况，对参数的处理方法，最好是能看到
他们的使用代码。而绝对不能凭空设想产品线“应该”是怎么样调用我们的接口的。
因为产品线可能以各种你设想不到的方式来调用你的接口。

2. 迁移过程必然会涉及到多个服务，与这些服务相关的一些参数细节，如pid，
配置等等，不仅要从对应服务负责人的口中得知，一定要看到实际的配置文件或
者代码，这样才能确定拿到的信息是准确无误的。这个时候不能相信人的记忆，
不能有任何的“应该”，“可能”，“也许”。因为一个细小的误差，就可能导致整个
迁移过程失败。

3. 多沟通，迁移是件涉及到方方面面的事，产品线，op，相关服务的负责人。
这个时候一定不能懒，要与每一个相关责任人沟通清楚方案、风险和操作细节。
这样才能保证整个过程的顺利实施。
